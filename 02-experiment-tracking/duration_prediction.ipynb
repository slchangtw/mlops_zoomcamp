{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block of code is used to add the root folder of the project to the path so that src can be imported.\n",
    "import os\n",
    "import sys\n",
    "\n",
    "root_folder = os.path.dirname(os.path.abspath(\"\"))\n",
    "if not root_folder in sys.path:\n",
    "    sys.path.append(root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from src import create_pipeline, read_trips, process_trips"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebooks shows how to track experiements and register model with MLflow. The noteboook consists of the following parts:\n",
    "\n",
    "1. Tracking the experiment from a Lasso model,\n",
    "2. Tuning hyperparameters with optuna MLflowCallback,\n",
    "3. Extending the model to XGBoost,\n",
    "4. Registering the best model in model registry."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of duration: 59.34\n",
      "Fraction of the records left after dropping the outliers: 0.9658903787344154\n",
      "Standard deviation of duration: 53.17\n",
      "Fraction of the records left after dropping the outliers: 0.9589450535835966\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../data\")\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "\n",
    "trips_train = read_trips(DATA_DIR, color=\"green\", year=\"2021\", month=\"1\")\n",
    "trips_val = read_trips(DATA_DIR, color=\"green\", year=\"2021\", month=\"2\")\n",
    "\n",
    "trips_train = process_trips(trips_train)\n",
    "trips_val = process_trips(trips_val)\n",
    "\n",
    "target = \"duration\"\n",
    "categorical_cols = [\"PU_DO\"]\n",
    "numerical_cols = [\"trip_distance\"]\n",
    "used_cols = categorical_cols + numerical_cols\n",
    "\n",
    "X_train = trips_train[used_cols]\n",
    "y_train = trips_train[target]\n",
    "\n",
    "X_val = trips_val[used_cols]\n",
    "y_val = trips_val[target]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MLflow to track experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical way to track experiments with MLflow is to wrap training code inside a MLflow context manager. \n",
    "\n",
    "Psuedo code:\n",
    "```python\n",
    "with mlflow.start_run():\n",
    "    # your training code\n",
    "    # parameters, metrics, artifacts you want to log by mlflow.log_<...>()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, we use MLflow to track the experiment from a Lasso model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"\n",
    "EXPERIMENT_NAME = \"nyc-taxi-experiment\"\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"model\", \"lasso\")\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    alpha = 0.01\n",
    "    pipe = create_pipeline(Lasso(alpha=alpha))\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    rmse = mean_squared_error(y_val, pipe.predict(X_val), squared=False)\n",
    "\n",
    "    mlflow.log_metric(\"rmse_val\", rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters with optuna MLflowCallback\n",
    "\n",
    "Optuna offers a MLflowCallback that can be used to track the hyperparameter tuning process with MLflow. \n",
    "\n",
    "Psuedo code:\n",
    "```python\n",
    "mlflc = MLflowCallback(\n",
    "    tracking_uri=MLFLOW_TRACKING_URI,\n",
    "    metric_name= ...,\n",
    ")\n",
    "\n",
    "@mlflc.track_in_mlflow()\n",
    "def objective(trial):\n",
    "    # parameters to tune\n",
    "    params = {param_name: trial.suggest_...}\n",
    "    # your training code\n",
    "    # objective function to minimize or maximize\n",
    "\n",
    "study = optuna.create_study(study_name=EXPERIMENT_NAME, direction= ...)\n",
    "study.optimize(objective, n_trials= ..., callbacks=[mlflc])\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example, we fine-tune the hyperparameters alpha of the Lasso model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6y/37g6x3_d0hv44_f4kt090bxh0000gn/T/ipykernel_2853/3795690691.py:1: ExperimentalWarning: MLflowCallback is experimental (supported from v1.4.0). The interface can change in the future.\n",
      "  mlflc = MLflowCallback(\n"
     ]
    }
   ],
   "source": [
    "mlflc = MLflowCallback(\n",
    "    tracking_uri=MLFLOW_TRACKING_URI,\n",
    "    metric_name=\"rmse_val\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6y/37g6x3_d0hv44_f4kt090bxh0000gn/T/ipykernel_2853/784763129.py:1: ExperimentalWarning: track_in_mlflow is experimental (supported from v2.9.0). The interface can change in the future.\n",
      "  @mlflc.track_in_mlflow()\n",
      "\u001b[32m[I 2023-06-03 12:44:42,373]\u001b[0m A new study created in memory with name: nyc-taxi-experiment\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 12:44:45,714]\u001b[0m Trial 0 finished with value: 12.212582895862711 and parameters: {'alpha': 0.7284515113077665}. Best is trial 0 with value: 12.212582895862711.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 12:44:49,223]\u001b[0m Trial 1 finished with value: 12.212582630408178 and parameters: {'alpha': 0.5088262461021089}. Best is trial 1 with value: 12.212582630408178.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 12:44:58,127]\u001b[0m Trial 2 finished with value: 10.1899072091622 and parameters: {'alpha': 0.0027013408039320433}. Best is trial 2 with value: 10.1899072091622.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 12:45:04,227]\u001b[0m Trial 3 finished with value: 11.43042026181242 and parameters: {'alpha': 0.016178469825871802}. Best is trial 2 with value: 10.1899072091622.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 12:45:10,246]\u001b[0m Trial 4 finished with value: 11.638993968649391 and parameters: {'alpha': 0.026365426607397546}. Best is trial 2 with value: 10.1899072091622.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 12:45:15,539]\u001b[0m Trial 5 finished with value: 11.949189225317284 and parameters: {'alpha': 0.05473970833211192}. Best is trial 2 with value: 10.1899072091622.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 12:45:20,790]\u001b[0m Trial 6 finished with value: 11.899345084332918 and parameters: {'alpha': 0.04877092977463091}. Best is trial 2 with value: 10.1899072091622.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 12:45:24,245]\u001b[0m Trial 7 finished with value: 12.212582388220081 and parameters: {'alpha': 0.30832335127694815}. Best is trial 2 with value: 10.1899072091622.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 12:45:32,059]\u001b[0m Trial 8 finished with value: 10.300718895840625 and parameters: {'alpha': 0.003072251217174698}. Best is trial 2 with value: 10.1899072091622.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 12:45:38,388]\u001b[0m Trial 9 finished with value: 11.661178297309066 and parameters: {'alpha': 0.027854139395960285}. Best is trial 2 with value: 10.1899072091622.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "@mlflc.track_in_mlflow()\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    params = {\"alpha\": trial.suggest_float(\"alpha\", 0.001, 1.0, log=True)}\n",
    "    pipe = create_pipeline(Lasso(**params))\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    rmse = mean_squared_error(y_val, pipe.predict(X_val), squared=False)\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metric(\"rmse_val\", rmse)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "study = optuna.create_study(study_name=EXPERIMENT_NAME, direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10, gc_after_trial=True, callbacks=[mlflc])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training, we can use `study.best_params` to reproduce the best model. The mean squared error of the best model is the smallest value in the log above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/03 12:46:26 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'ae9592374f154178963e6aee05fc0cb6', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.1899072091622"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best model by study.trial\n",
    "best_model = create_pipeline(Lasso(**study.best_params))\n",
    "best_model.fit(X_train, y_train)\n",
    "mean_squared_error(y_val, best_model.predict(X_val), squared=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use xgboost as predictor\n",
    "\n",
    "We use XGBoost as the predictor to show how to define a complex hyperparameter search space `params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6y/37g6x3_d0hv44_f4kt090bxh0000gn/T/ipykernel_2853/2999725602.py:1: ExperimentalWarning: track_in_mlflow is experimental (supported from v2.9.0). The interface can change in the future.\n",
      "  @mlflc.track_in_mlflow()\n",
      "\u001b[32m[I 2023-06-03 13:00:28,430]\u001b[0m A new study created in memory with name: nyc-taxi-experiment\u001b[0m\n",
      "2023/06/03 13:00:28 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('dict_transformer', <src.create_model.DictTransformer object at 0x28c14a0d0>), ('vectorizer', DictVectorizer()), ('predictor', XGBRegressor(alpha=0.018716682719060657, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.1723126708454834, eval_metric=None,\n",
      "             feature_types=None, gamma=None, gpu_id=None, grow_policy=None,...`\n",
      "2023/06/03 13:00:28 WARNING mlflow.utils: Truncated the value of the key `predictor`. Truncated value: `XGBRegressor(alpha=0.018716682719060657, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.1723126708454834, eval_metric=None,\n",
      "             feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             lambda=4.586198333655434, learning_rate=None, max_...`\n",
      "\u001b[32m[I 2023-06-03 13:00:31,221]\u001b[0m Trial 0 finished with value: 6.55527410586997 and parameters: {'max_depth': 10, 'eta': 0.1723126708454834, 'alpha': 0.018716682719060657, 'lambda': 4.586198333655434, 'min_child_weight': 4}. Best is trial 0 with value: 6.55527410586997.\u001b[0m\n",
      "2023/06/03 13:00:31 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('dict_transformer', <src.create_model.DictTransformer object at 0x28d41dd00>), ('vectorizer', DictVectorizer()), ('predictor', XGBRegressor(alpha=0.02634716079902015, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.014683717959721544,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             gro...`\n",
      "2023/06/03 13:00:31 WARNING mlflow.utils: Truncated the value of the key `predictor`. Truncated value: `XGBRegressor(alpha=0.02634716079902015, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.014683717959721544,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, lambda=0.011790243769151363,\n",
      "             learnin...`\n",
      "\u001b[32m[I 2023-06-03 13:00:34,137]\u001b[0m Trial 1 finished with value: 8.65493145648402 and parameters: {'max_depth': 8, 'eta': 0.014683717959721544, 'alpha': 0.02634716079902015, 'lambda': 0.011790243769151363, 'min_child_weight': 7}. Best is trial 0 with value: 6.55527410586997.\u001b[0m\n",
      "2023/06/03 13:00:34 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('dict_transformer', <src.create_model.DictTransformer object at 0x289b53310>), ('vectorizer', DictVectorizer()), ('predictor', XGBRegressor(alpha=0.022117370609184082, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.03976800575446704,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             gro...`\n",
      "2023/06/03 13:00:34 WARNING mlflow.utils: Truncated the value of the key `predictor`. Truncated value: `XGBRegressor(alpha=0.022117370609184082, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.03976800575446704,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, lambda=0.0713330076120734,\n",
      "             learning_...`\n",
      "\u001b[32m[I 2023-06-03 13:00:36,637]\u001b[0m Trial 2 finished with value: 6.759343269549544 and parameters: {'max_depth': 6, 'eta': 0.03976800575446704, 'alpha': 0.022117370609184082, 'lambda': 0.0713330076120734, 'min_child_weight': 3}. Best is trial 0 with value: 6.55527410586997.\u001b[0m\n",
      "2023/06/03 13:00:36 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('dict_transformer', <src.create_model.DictTransformer object at 0x28d7fc9a0>), ('vectorizer', DictVectorizer()), ('predictor', XGBRegressor(alpha=0.7541010319005674, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.01563229645781922,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             grow_...`\n",
      "2023/06/03 13:00:36 WARNING mlflow.utils: Truncated the value of the key `predictor`. Truncated value: `XGBRegressor(alpha=0.7541010319005674, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.01563229645781922,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, lambda=0.013461894694675122,\n",
      "             learning_...`\n",
      "\u001b[32m[I 2023-06-03 13:00:39,245]\u001b[0m Trial 3 finished with value: 8.424670987754538 and parameters: {'max_depth': 6, 'eta': 0.01563229645781922, 'alpha': 0.7541010319005674, 'lambda': 0.013461894694675122, 'min_child_weight': 5}. Best is trial 0 with value: 6.55527410586997.\u001b[0m\n",
      "2023/06/03 13:00:39 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('dict_transformer', <src.create_model.DictTransformer object at 0x28d5baeb0>), ('vectorizer', DictVectorizer()), ('predictor', XGBRegressor(alpha=0.4992812259677942, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.028292879522591546,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             grow...`\n",
      "2023/06/03 13:00:39 WARNING mlflow.utils: Truncated the value of the key `predictor`. Truncated value: `XGBRegressor(alpha=0.4992812259677942, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.028292879522591546,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, lambda=0.5095527863222247,\n",
      "             learning_r...`\n",
      "\u001b[32m[I 2023-06-03 13:00:41,811]\u001b[0m Trial 4 finished with value: 7.003107427436162 and parameters: {'max_depth': 6, 'eta': 0.028292879522591546, 'alpha': 0.4992812259677942, 'lambda': 0.5095527863222247, 'min_child_weight': 10}. Best is trial 0 with value: 6.55527410586997.\u001b[0m\n",
      "2023/06/03 13:00:41 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('dict_transformer', <src.create_model.DictTransformer object at 0x28e348850>), ('vectorizer', DictVectorizer()), ('predictor', XGBRegressor(alpha=0.06012964824564713, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.021819674148316558,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             gro...`\n",
      "2023/06/03 13:00:41 WARNING mlflow.utils: Truncated the value of the key `predictor`. Truncated value: `XGBRegressor(alpha=0.06012964824564713, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.021819674148316558,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, lambda=3.6516483144202723,\n",
      "             learning_...`\n",
      "\u001b[32m[I 2023-06-03 13:00:44,286]\u001b[0m Trial 5 finished with value: 7.440123730939428 and parameters: {'max_depth': 5, 'eta': 0.021819674148316558, 'alpha': 0.06012964824564713, 'lambda': 3.6516483144202723, 'min_child_weight': 4}. Best is trial 0 with value: 6.55527410586997.\u001b[0m\n",
      "2023/06/03 13:00:44 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('dict_transformer', <src.create_model.DictTransformer object at 0x28d61a310>), ('vectorizer', DictVectorizer()), ('predictor', XGBRegressor(alpha=0.21382040694769577, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.011678624090245848,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             gro...`\n",
      "2023/06/03 13:00:44 WARNING mlflow.utils: Truncated the value of the key `predictor`. Truncated value: `XGBRegressor(alpha=0.21382040694769577, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.011678624090245848,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, lambda=0.06374962545257017,\n",
      "             learning...`\n",
      "\u001b[32m[I 2023-06-03 13:00:46,862]\u001b[0m Trial 6 finished with value: 9.74466920982591 and parameters: {'max_depth': 6, 'eta': 0.011678624090245848, 'alpha': 0.21382040694769577, 'lambda': 0.06374962545257017, 'min_child_weight': 10}. Best is trial 0 with value: 6.55527410586997.\u001b[0m\n",
      "2023/06/03 13:00:46 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('dict_transformer', <src.create_model.DictTransformer object at 0x28d46a0a0>), ('vectorizer', DictVectorizer()), ('predictor', XGBRegressor(alpha=0.016835650274789088, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.03912590365770722,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             gro...`\n",
      "2023/06/03 13:00:46 WARNING mlflow.utils: Truncated the value of the key `predictor`. Truncated value: `XGBRegressor(alpha=0.016835650274789088, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.03912590365770722,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, lambda=0.03308173472304837,\n",
      "             learning...`\n",
      "\u001b[32m[I 2023-06-03 13:00:49,859]\u001b[0m Trial 7 finished with value: 6.707000410017302 and parameters: {'max_depth': 9, 'eta': 0.03912590365770722, 'alpha': 0.016835650274789088, 'lambda': 0.03308173472304837, 'min_child_weight': 5}. Best is trial 0 with value: 6.55527410586997.\u001b[0m\n",
      "2023/06/03 13:00:49 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('dict_transformer', <src.create_model.DictTransformer object at 0x28d687af0>), ('vectorizer', DictVectorizer()), ('predictor', XGBRegressor(alpha=4.251860109147366, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.015960125506338314,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             grow_...`\n",
      "2023/06/03 13:00:49 WARNING mlflow.utils: Truncated the value of the key `predictor`. Truncated value: `XGBRegressor(alpha=4.251860109147366, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.015960125506338314,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, lambda=3.8528040877133733,\n",
      "             learning_ra...`\n",
      "\u001b[32m[I 2023-06-03 13:00:52,773]\u001b[0m Trial 8 finished with value: 8.327237828744673 and parameters: {'max_depth': 8, 'eta': 0.015960125506338314, 'alpha': 4.251860109147366, 'lambda': 3.8528040877133733, 'min_child_weight': 5}. Best is trial 0 with value: 6.55527410586997.\u001b[0m\n",
      "2023/06/03 13:00:52 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('dict_transformer', <src.create_model.DictTransformer object at 0x28a0a6220>), ('vectorizer', DictVectorizer()), ('predictor', XGBRegressor(alpha=4.135786248247304, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.024148468928102518,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             grow_...`\n",
      "2023/06/03 13:00:52 WARNING mlflow.utils: Truncated the value of the key `predictor`. Truncated value: `XGBRegressor(alpha=4.135786248247304, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.024148468928102518,\n",
      "             eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, lambda=0.03107960155259224,\n",
      "             learning_r...`\n",
      "\u001b[32m[I 2023-06-03 13:00:55,101]\u001b[0m Trial 9 finished with value: 7.270407539497713 and parameters: {'max_depth': 4, 'eta': 0.024148468928102518, 'alpha': 4.135786248247304, 'lambda': 0.03107960155259224, 'min_child_weight': 9}. Best is trial 0 with value: 6.55527410586997.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "@mlflc.track_in_mlflow()\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 0.01, 0.4, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0.01, 5, log=True),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 0.01, 5, log=True),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "    }\n",
    "    pipe = create_pipeline(XGBRegressor(**params, random_state=42)) \n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    rmse = mean_squared_error(y_val, pipe.predict(X_val), squared=False)\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metric(\"rmse_val\", rmse)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "study = optuna.create_study(study_name=EXPERIMENT_NAME, direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10, gc_after_trial=True, callbacks=[mlflc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/03 13:01:01 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '4f4e8b085d014fa5b7ac136e0f3d667a', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/06/03 13:01:01 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('dict_transformer', <src.create_model.DictTransformer object at 0x289b2b520>), ('vectorizer', DictVectorizer()), ('predictor', XGBRegressor(alpha=0.018716682719060657, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.1723126708454834, eval_metric=None,\n",
      "             feature_types=None, gamma=None, gpu_id=None, grow_policy=None,...`\n",
      "2023/06/03 13:01:01 WARNING mlflow.utils: Truncated the value of the key `predictor`. Truncated value: `XGBRegressor(alpha=0.018716682719060657, base_score=None, booster=None,\n",
      "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eta=0.1723126708454834, eval_metric=None,\n",
      "             feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             lambda=4.586198333655434, learning_rate=None, max_...`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.55527410586997"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = create_pipeline(XGBRegressor(**study.best_params, random_state=42)) \n",
    "best_model.fit(X_train, y_train)\n",
    "mean_squared_error(y_val, best_model.predict(X_val), squared=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Register the best model to the model registry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We can use `search_runs()` from `MlflowClient` to get runs from an experiment by conditionally filtering on the metrics. \n",
    "2. When having the run with desired performance, we can use `create_model_version()` to register the model to the model registry.\n",
    "3. We can transit the model into different stages (Staging or Production) by `transition_model_version_stage()`.\n",
    "4. The model can be loaded by `mlflow.pyfunc.load_model()` from the model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "experiment_id = client.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment_id,\n",
    "    filter_string=\"metrics.rmse_val < 7\",\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.rmse_val ASC\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run id: e677ee00a99d40dea94eaee4a2ec4d6a\n",
      "Valid RMSE: 6.503431247273923\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Best run id: {runs[0].info.run_id}\\nValid RMSE: {runs[0].data.metrics['rmse_val']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run_id = runs[0].info.run_id\n",
    "model_uri = f\"runs:/{best_run_id}/models\"\n",
    "model_name = \"nyc-taxi-regressor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/03 13:01:25 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: nyc-taxi-regressor, version 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1685790085313, current_stage='None', description=None, last_updated_timestamp=1685790085313, name='nyc-taxi-regressor', run_id='e677ee00a99d40dea94eaee4a2ec4d6a', run_link=None, source='mlruns/1/e677ee00a99d40dea94eaee4a2ec4d6a/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_registered_model(model_name)\n",
    "client.create_model_version(\n",
    "    name=model_name,\n",
    "    source=f\"mlruns/{experiment_id}/{best_run_id}/artifacts/model\",\n",
    "    run_id=best_run_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1685790085313, current_stage='Staging', description=None, last_updated_timestamp=1685790089209, name='nyc-taxi-regressor', run_id='e677ee00a99d40dea94eaee4a2ec4d6a', run_link=None, source='mlruns/1/e677ee00a99d40dea94eaee4a2ec4d6a/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version = 1\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name, version=version, stage=\"Staging\", archive_existing_versions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/03 13:01:35 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - mlflow (current: 2.3.2, required: mlflow==2.3)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([17.151312 ,  7.1795797, 18.21909  , 24.356016 ,  9.369879 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/Staging\")\n",
    "model.predict(X_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1685790085313, current_stage='Production', description=None, last_updated_timestamp=1685790118728, name='nyc-taxi-regressor', run_id='e677ee00a99d40dea94eaee4a2ec4d6a', run_link=None, source='mlruns/1/e677ee00a99d40dea94eaee4a2ec4d6a/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version = 1\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name, version=version, stage=\"Production\", archive_existing_versions=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from src import read_trips, process_trips, save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data\")\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"\n",
    "EXPERIMENT_NAME = \"nyc-taxi-tips-experiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.2'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of duration: 78.22\n",
      "Fraction of the records left after dropping the outliers: 0.9537242979438355\n",
      "Standard deviation of duration: 78.88\n",
      "Fraction of the records left after dropping the outliers: 0.9524200636896786\n",
      "Standard deviation of duration: 78.87\n",
      "Fraction of the records left after dropping the outliers: 0.948686606312948\n"
     ]
    }
   ],
   "source": [
    "trips_train = read_trips(DATA_DIR, color=\"green\", year=\"2022\", month=\"1\")\n",
    "trips_val = read_trips(DATA_DIR, color=\"green\", year=\"2022\", month=\"2\")\n",
    "trips_test = read_trips(DATA_DIR, color=\"green\", year=\"2022\", month=\"3\")\n",
    "\n",
    "trips_train = process_trips(trips_train)\n",
    "trips_val = process_trips(trips_val)\n",
    "trips_test = process_trips(trips_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153660"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the homework, we need to predict the tips amount.\n",
    "target = \"tip_amount\"\n",
    "categorical_cols = [\"PU_DO\"]\n",
    "numerical_cols = [\"trip_distance\"]\n",
    "used_cols = categorical_cols + numerical_cols\n",
    "\n",
    "dv = DictVectorizer()\n",
    "X_hw = dv.fit_transform(trips_train[used_cols].to_dict(orient=\"records\"))\n",
    "\n",
    "save_model(MODEL_DIR, \"dv.pkl\", dv)\n",
    "os.path.getsize(MODEL_DIR / \"dv.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = trips_train[used_cols], trips_train[target]\n",
    "X_val, y_val = trips_val[used_cols], trips_val[target]\n",
    "X_test, y_test = trips_test[used_cols], trips_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6y/37g6x3_d0hv44_f4kt090bxh0000gn/T/ipykernel_2853/3992195366.py:1: ExperimentalWarning: MLflowCallback is experimental (supported from v1.4.0). The interface can change in the future.\n",
      "  mlflc = MLflowCallback(\n",
      "/var/folders/6y/37g6x3_d0hv44_f4kt090bxh0000gn/T/ipykernel_2853/3992195366.py:7: ExperimentalWarning: track_in_mlflow is experimental (supported from v2.9.0). The interface can change in the future.\n",
      "  @mlflc.track_in_mlflow()\n",
      "\u001b[32m[I 2023-06-03 13:04:45,760]\u001b[0m A new study created in memory with name: nyc-taxi-tips-experiment\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 13:04:47,934]\u001b[0m Trial 0 finished with value: 2.451379690825458 and parameters: {'n_estimators': 25, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 2.451379690825458.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 13:04:49,642]\u001b[0m Trial 1 finished with value: 2.4667366020368333 and parameters: {'n_estimators': 16, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 0 with value: 2.451379690825458.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 13:04:51,863]\u001b[0m Trial 2 finished with value: 2.449827329704216 and parameters: {'n_estimators': 34, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 2 with value: 2.449827329704216.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 13:04:53,727]\u001b[0m Trial 3 finished with value: 2.460983516558473 and parameters: {'n_estimators': 44, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 2.449827329704216.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 13:04:55,706]\u001b[0m Trial 4 finished with value: 2.453877262701052 and parameters: {'n_estimators': 22, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 2 with value: 2.449827329704216.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 13:04:57,463]\u001b[0m Trial 5 finished with value: 2.4720122094960733 and parameters: {'n_estimators': 35, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 2 with value: 2.449827329704216.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 13:04:59,634]\u001b[0m Trial 6 finished with value: 2.4516421799356767 and parameters: {'n_estimators': 28, 'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 2 with value: 2.449827329704216.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 13:05:01,287]\u001b[0m Trial 7 finished with value: 2.5374040268274087 and parameters: {'n_estimators': 34, 'max_depth': 1, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 2 with value: 2.449827329704216.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 13:05:03,220]\u001b[0m Trial 8 finished with value: 2.455971238567075 and parameters: {'n_estimators': 12, 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 2 with value: 2.449827329704216.\u001b[0m\n",
      "\u001b[32m[I 2023-06-03 13:05:04,836]\u001b[0m Trial 9 finished with value: 2.486106021576535 and parameters: {'n_estimators': 22, 'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 2 with value: 2.449827329704216.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mlflc = MLflowCallback(\n",
    "    tracking_uri=MLFLOW_TRACKING_URI,\n",
    "    metric_name=\"rmse_val\",\n",
    ")\n",
    "\n",
    "\n",
    "@mlflc.track_in_mlflow()\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 50, 1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 20, 1),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10, 1),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 4, 1),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "    }\n",
    "    pipe = create_pipeline(RandomForestRegressor(**params))\n",
    "    pipe.fit(X_train, y_train)\n",
    "    rmse = mean_squared_error(y_val, pipe.predict(X_val), squared=False)\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metric(\"rmse_val\", rmse)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=EXPERIMENT_NAME, direction=\"minimize\", sampler=TPESampler(seed=42)\n",
    ")\n",
    "study.optimize(objective, n_trials=10, gc_after_trial=True, callbacks=[mlflc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "experiment_id = client.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment_id,\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.rmse_val ASC\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/03 13:10:34 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '6db9398c5bd445e381f54e02858cff62', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/06/03 13:10:36 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd3bd7eb7523442088f666388651d650d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run id: 04376d6f198d46b387ba3e488696ede4. Test RMSE: 2.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/03 13:10:38 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '168c5210f50f4188b31ba305c603d437', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run id: 8919149a24f946fdb27758e108f7a35a. Test RMSE: 2.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/03 13:10:40 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '4e79d1c853d041c8bae17bccf03a16f4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run id: cfecc5956d3a4ed396f01484a80123f4. Test RMSE: 2.292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/03 13:10:42 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'a58a82cc66da4f36b3232f0ea078669f', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run id: b6a1eb99cdf3429f89d03c29011bb58f. Test RMSE: 2.299\n",
      "Run id: 1f9550f9bcb94d7e8654f321b4f39ae9. Test RMSE: 2.291\n"
     ]
    }
   ],
   "source": [
    "for run in runs:\n",
    "    rf_params = [\n",
    "        \"n_estimators\",\n",
    "        \"max_depth\",\n",
    "        \"min_samples_split\",\n",
    "        \"min_samples_leaf\",\n",
    "        \"random_state\",\n",
    "        \"n_jobs\",\n",
    "    ]\n",
    "    params = {k: int(v) for k, v in run.data.params.items() if k in rf_params}\n",
    "    pipe = create_pipeline(RandomForestRegressor(**params))\n",
    "    pipe.fit(X_train, y_train)\n",
    "    rmse_test = mean_squared_error(y_test, pipe.predict(X_test), squared=False)\n",
    "\n",
    "    print(f\"Run id: {run.info.run_id}. Test RMSE: {rmse_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
